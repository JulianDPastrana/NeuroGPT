#!/usr/bin/env python3
"""
IMBALANCE & STRATIFIED K-FOLD SOLUTION
======================================

PROBLEM ANALYSIS:
-----------------
Your training logs show:
  - Eval accuracy: 0.27-0.32 (very low)
  - This is likely due to:
    1. EXTREME CLASS IMBALANCE in the dataset
    2. Model predicting mostly class 1 (majority class)
    3. Validation set has imbalanced class distribution
    4. No stratification means some folds might have skewed splits

EXAMPLE OF IMBALANCE EFFECT:
If train/val sets have 80% class 1 and 20% class 0:
  - Baseline accuracy (always predict 1): ~80%
  - Your observed accuracy: 27-32% (model worse than baseline!)
  - This suggests label polarity mismatch or inverted logic

SOLUTION OVERVIEW:
------------------
This codebase now includes:

1. stratified_fold_generator.py
   ✓ Detects class imbalance in your dataset
   ✓ Uses StratifiedGroupKFold for balanced splits
   ✓ Ensures each fold maintains original class distribution
   ✓ Creates manifest files compatible with train_gpt.py

2. check_label_imbalance.py
   ✓ Analyzes label distribution across train/val/test
   ✓ Reports imbalance ratio
   ✓ Diagnoses root cause of low accuracy
   ✓ Recommends fixes

USAGE GUIDE:
------------

Step 1: Check for imbalance
  cd scripts
  python check_label_imbalance.py \\
    --data ../../data/adhd_control_npz/ \\
    --manifest .adhd_fold_1_files.txt

Expected output:
  - Label distribution breakdown
  - Imbalance diagnosis
  - Severity classification

Step 2: Generate stratified folds (if imbalanced)
  python stratified_fold_generator.py \\
    --data ../../data/adhd_control_npz/ \\
    --n-splits 10 \\
    --val-ratio 0.2

This creates:
  - .adhd_fold_1_files.txt through .adhd_fold_10_files.txt
  - Each with balanced [TRAIN] [VAL] [TEST] sections
  - Ready to use with train_gpt.py

Step 3: Use generated manifests in training
  cd ../src
  python train_gpt.py \\
    --training-style='decoding' \\
    --num-decoding-classes=2 \\
    --fold-manifest-file="../scripts/.adhd_fold_1_files.txt" \\
    ... other args ...

TECHNICAL DETAILS:
------------------

What is StratifiedGroupKFold?
  - Standard GroupKFold: splits subjects into groups
  - StratifiedGroupKFold: ALSO preserves class distribution
  - Result: balanced train/val/test splits

Class Imbalance Handling (additional fix if needed):
  If data is extremely imbalanced (>70% one class):
  
  Option 1: pos_weight in BCEWithLogitsLoss
    loss_fn = BCEWithLogitsLoss(pos_weight=torch.tensor(weight))
    where weight = n_neg / n_pos
    
  Option 2: Class weights
    weights = [1.0/n_class0, 1.0/n_class1]
    per_sample_weights = [weights[label] for label in labels]

WHAT QUESTIONS DO YOU HAVE?
---------------------------

Please clarify:

1. Data Location
   - Where is your ADHD dataset? (I tried ../../data/adhd_control_npz but it doesn't exist)
   - Are labels in .mat files in true_labels/ subdirectory?

2. Label Format
   - Are labels stored as integers (1,2) or (0,1)?
   - Are they in .mat files or embedded in .npz?

3. Expected Imbalance
   - Do you expect the dataset to have imbalanced classes?
   - Or should classes be roughly 50-50?

4. Your Goal
   - Do you want me to integrate stratified fold generation into
     finetune_adhd_10fold.sh automatically?
   - Or will you run the scripts manually?

NEXT STEPS:
-----------
1. Provide data path and label location
2. Run check_label_imbalance.py to detect imbalance
3. If imbalanced: Run stratified_fold_generator.py
4. Update finetune_adhd_10fold.sh to use generated manifests
5. Rerun training with balanced folds

This should significantly improve your eval accuracy!
"""
